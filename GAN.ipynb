{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9i1BdU778o1tsVhgP1enb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarveshD7/Vanilla-GAN-Pytorch/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gXOHMhegLmUj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.modules.activation import LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_dim):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(img_dim, 128),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(128, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n"
      ],
      "metadata": {
        "id": "WBNEwX9xMGFr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, img_dim):\n",
        "    super().__init__()\n",
        "   # z_dim-> Dimension of Noise\n",
        "   #  img_dim-> Dimension of Image input ->(Here in case of MNIST) 28x28x1 = 784\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(z_dim, 256),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(256, img_dim),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)"
      ],
      "metadata": {
        "id": "MrZ1GgLgQHp8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "lr = 3e-4\n",
        "z_dim = 64 # Can also be 128, 256\n",
        "image_dim = 28*28*1\n",
        "batch_size = 32\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "w_ewC3pLQH-c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc = Discriminator(image_dim).to(device)\n",
        "gen = Generator(z_dim, image_dim).to(device)\n",
        "fixed_noise = torch.randn(batch_size, z_dim).to(device)"
      ],
      "metadata": {
        "id": "EKRBmhRZRAeG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, ), (0.5,))]\n",
        ")"
      ],
      "metadata": {
        "id": "Sge404flR3vw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset  = datasets.MNIST(root = \"/content/dataset/\", transform = transforms, download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSV8ZgKaSmMu",
        "outputId": "66b2cfd0-8fd8-4c2d-d688-a9bc1055bb4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 144333046.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/dataset/MNIST/raw/train-images-idx3-ubyte.gz to /content/dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 33007001.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to /content/dataset/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 37140279.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/dataset/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14860006.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/dataset/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
        "opt_disc = optim.Adam(disc.parameters(), lr = lr)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr = lr)\n",
        "criterion = nn.BCELoss()\n",
        "writer_fake = SummaryWriter(f\"/content/runs/GAN_MNIST/fake\")\n",
        "writer_real = SummaryWriter(f\"/content/runs/GAN_MNIST/real\")\n",
        "step = 0\n"
      ],
      "metadata": {
        "id": "Za9F9tN9Swmm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(f\"Started Epoch-> {epoch+1}\")\n",
        "  for batch_idx, (real, _) in enumerate(loader):  # We can ignore the label since we are only considered with the image being a real one\n",
        "    real = real.view(-1, 784)  # Flattening the image\n",
        "    batch_size = real.shape[0]\n",
        "\n",
        "    # Training the discriminator---> Maximize log(D(real)) + log(1-D(G(z))\n",
        "    noise = torch.randn(batch_size, z_dim).to(device)\n",
        "    fake = gen(noise)\n",
        "    disc_real = disc(real).view(-1)  # The output of the Discriminator on the real images Flattened\n",
        "    lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "    # criterion-> BCE Loss-> ℓ(x,y) = -wn*[yn . logxn +(1-yn) . log(1-xn)] -> We are passing y as all ones so ulitmately this term will become the first component of the Discriminator Loss\n",
        "    disc_fake = disc(fake).view(-1)\n",
        "    lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "    # criterion-> BCE Loss-> ℓ(x,y) = -wn*[yn . logxn +(1-yn) . log(1-xn)] -> We are passing y as all zeros so ulitmately this term will become the second component of the Discriminator Loss\n",
        "    lossD = (lossD_real + lossD_fake) / 2\n",
        "    disc.zero_grad()\n",
        "    lossD.backward(retain_graph = True)\n",
        "    opt_disc.step()\n",
        "\n",
        "    # Training the discriminator---> Minimize log(1-D(G(z)) <----> Maximize log(D(g(z)))\n",
        "    output = disc(fake).view(-1)\n",
        "    lossG = criterion(output, torch.ones_like(output))\n",
        "    gen.zero_grad()\n",
        "    lossG.backward()\n",
        "    opt_gen.step()\n",
        "  print(f\"Completed Epoch-> {epoch+1}\")\n"
      ],
      "metadata": {
        "id": "27-oKXY1TlZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Important Points to note***\n",
        "***GANs are sensitive to the hyperparameters. So better results may be obtained by hyperparameter tuning and experimenting with the same. Results can also be improved by using CNNs in the Discriminator and the Generator which is DCGAN(Deep Convolution GAN)***\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "s0FUwcWW0X9_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUH9XlklmgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RsLfpJUvm4G1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}